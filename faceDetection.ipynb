{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install labelme tensorflow opencv-python matplotlib albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "import json \n",
    "import numpy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data','images')\n",
    "number_images = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "for imgnum in range(number_images):\n",
    "    print(\"Collecting image {}\".format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(IMAGES_PATH, f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.list_files('data\\\\images\\\\*.jpg', shuffle='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(x):\n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.as_numpy_generator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = images.batch(4).as_numpy_iterator()\n",
    "plot_images = image_generator.next()\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, image in enumerate(plot_images):\n",
    "    ax[idx].imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in [\"train\", \"test\", \"val\"]:\n",
    "    for file in os.listdir(os.path.join(\"data\", folder, \"images\")):\n",
    "        filename = file.split(\".\")[0] + \".json\"\n",
    "        existing_filepath = os.path.join(\"data\", \"labels\", filename)\n",
    "        if os.path.exists(existing_filepath):\n",
    "            new_filepath = os.path.join(\"data\", folder, \"labels\", filename)\n",
    "            os.replace(existing_filepath, new_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "\n",
    "augmentor = alb.Compose(\n",
    "    [\n",
    "        alb.RandomCrop(width=450, height=450),\n",
    "        alb.HorizontalFlip(p=0.5),\n",
    "        alb.RandomBrightnessContrast(p=0.2),\n",
    "        alb.RandomGamma(p=0.2),\n",
    "        alb.RGBShift(p=0.2),\n",
    "        alb.VerticalFlip(p=0.5),\n",
    "    ],\n",
    "    bbox_params=alb.BboxParams(format=\"albumentations\", label_fields=[\"class_labels\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\n",
    "    os.path.join(\"data\", \"train\", \"images\", \"ffd85fc5-cc1a-11ec-bfb8-a0cec8d2d278.jpg\")\n",
    ")\n",
    "with open(\n",
    "    os.path.join(\n",
    "        \"data\", \"train\", \"labels\", \"ffd85fc5-cc1a-11ec-bfb8-a0cec8d2d278.json\"\n",
    "    ),\n",
    "    \"r\",\n",
    ") as f:\n",
    "    label = json.load(f)\n",
    "label[\"shapes\"][0][\"points\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [0, 0, 0, 0]\n",
    "coords[0] = label[\"shapes\"][0][\"points\"][0][0]\n",
    "coords[1] = label[\"shapes\"][0][\"points\"][0][1]\n",
    "coords[2] = label[\"shapes\"][0][\"points\"][1][0]\n",
    "coords[3] = label[\"shapes\"][0][\"points\"][1][1]\n",
    "coords = list(np.divide(coords, [640, 480, 640, 480]))\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img, bboxes=[coords], class_labels=[\"face\"])\n",
    "augmented[\"bboxes\"][0][2:]\n",
    "augmented[\"bboxes\"]\n",
    "cv2.rectangle(\n",
    "    augmented[\"image\"],\n",
    "    tuple(np.multiply(augmented[\"bboxes\"][0][:2], [450, 450]).astype(int)),\n",
    "    tuple(np.multiply(augmented[\"bboxes\"][0][2:], [450, 450]).astype(int)),\n",
    "    (255, 0, 0),\n",
    "    2,\n",
    ")\n",
    "\n",
    "plt.imshow(augmented[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [640,480,640,480]))\n",
    "\n",
    "        try: \n",
    "            for x in range(60):\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.list_files(\n",
    "    \"aug_data\\\\train\\\\images\\\\*.jpg\", shuffle=False\n",
    ")\n",
    "train_images = train_images.map(load_image)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (120, 120)))\n",
    "train_images = train_images.map(lambda x: x / 255)\n",
    "test_images = tf.data.Dataset.list_files(\"aug_data\\\\test\\\\images\\\\*.jpg\", shuffle=False)\n",
    "test_images = test_images.map(load_image)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (120, 120)))\n",
    "test_images = test_images.map(lambda x: x / 255)\n",
    "val_images = tf.data.Dataset.list_files(\"aug_data\\\\val\\\\images\\\\*.jpg\", shuffle=False)\n",
    "val_images = val_images.map(load_image)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (120, 120)))\n",
    "val_images = val_images.map(lambda x: x / 255)\n",
    "train_images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), \"r\", encoding=\"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "\n",
    "    return [label[\"class\"]], label[\"bbox\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
